---
title: "[Paper] GPT-4 Technical Report"
excerpt: "오픈 AI 개발, 멀티모달 입력을 지원하는 GPT-4 모델 기술 보고서"

categories:
  - Paper
tags:
  - [Paper, llm, Generative AI]

permalink: /paper/gpt4-tech-report

toc: true
toc_sticky: true

date: 2023-10-01
last_modified_at: 2023-10-01
---

GPT-4 모델 공개 : 2023.03.14 **(Report: 2023.03.27)** <br>
올해 초 오픈 AI가 개발한 멀티모달 입력을 지원하는 GPT-4 모델이 공개 되었습니다.<br>

- 이미 웹 상에 잘 정리된 글이 많고 현재도 계속 연구가 진행되는 분야이기 때문에 정리하기에는 늦은 감이 있지만, 처음 화두가 된 논문을 시작으로 하나씩 정리해가면서 **LLM(Large Language model)**이 현재 어떤 방향으로 나아가고 있고, 향후 어떤 방향으로 나아갈지 탐구해보고자 합니다. <br>

---
## Technical Report
### 7줄 요약

- 질문을 멀티모달(이미지+텍스트)로 입력 받고, 텍스트로 답변합니다.<br>
- 여러 질문을 누적, 농담(유머)을 비롯한 언어의 맥락을 파악해서 답변합니다.<br>
- 외국어 이해능력이 향상되었습니다. (전세계 26개 언어 중 한국어 포함 24개에서 GPT-3.5 영어 보다 높은 성능)<br>
- 미국의 모의 변호사 시험 성적에서 상위 10%에 해당하는 수준을 보였습니다. (GPT-3.5는 하위 10%)<br>
- 아직까지는 환각 현상(illusination; hallucination)이 있으므로 답변을 완전히 신뢰할 수 없습니다.<br>
- 차트 해석, 논문 요약, 밈(meme) 해석, 프랑스어 물리학 문제 풀이 등이 가능합니다.<br>
- 현재 ChatGPT는 GPT-3.5로 동작되고 있으며 GPT-4를 이용하려면 월 20달러 유료멤버십을 이용해야 하지만, MS의 Bing 검색엔진(Bing Chat)을 사용하면 GPT-4를 체험해볼 수 있으니 참고하면 좋을 것 같습니다.<br><br>


### 1. 기능
- 기존 GPT-3.5까지는 질문할 때 텍스트 입력만 가능 했었지만,  GPT-4에는 **이미지 입력 기능**이 추가되었습니다.<br>
- 아래와 같이 텍스트와 이미지를 입력 값(멀티모달)으로 넣고, 답변을 텍스트로 받을 수 있습니다.<br>

<img src="/assets/images/posts_img/gpt4-tech-report/input_example.jpg" alt="input" width="100%">

입력값으로 넣은 이미지를 잘 살펴보면 VGA 케이블(컴퓨터 모니터 연결 선, HDMI 이전에 사용되던 선)의 모양에 끝 부분이 애플기기 충전용인 라이트닝 커넥터가 연결돼 있습니다.<br>
- 사용자의 질문 요구대로 여러 개의 이미지인데도 각 특징을 파악하고, 다시 한 번 하나로 통합해서 하나의 맥락으로 이어 설명하는 듯한 답변을 합니다.<br>

- 아래 [표]에서 가장 상단의 “Uniform Bar Exam (MBE+MEE+MPT)”은 미국 변호사 모의 시험이고 266점 이상이면 합격 수준이라고 할 수 있습니다.<br>
GPT-4는 이 시험에서 298점으로 상위 10%의 성능을 보였습니다. GPT-3.5는 213점을 획득, 하위 10%임을 생각해보면 매우 높아진 성능입니다.<br>
미국 대학입학자격시험(SAT)에서도 읽기 & 쓰기와 수학 과목에서 상위 10~11% 안에 들었으며, 나머지 다른 시험의 점수들도 살펴보면 점수가 눈에 띄게 상승했습니다.

<img src="/assets/images/posts_img/gpt4-tech-report/model_sc.jpg" alt="score" width="100%">

- 성능 벤치마크에서도 기존에 공개된 딥마인드의 '친칠라(Chinchilla)', 구글의 '팜(PaLM)' 같은 SOTA 모델(State-of-the-art; 현재 최고 수준의 결과를 가진 모델) 보다 더 높은 성능을 보여줬습니다(2023년 3월 기준).

<img src="/assets/images/posts_img/gpt4-tech-report/model_ot.jpg" alt="other model" width="100%">

- MMLU(대규모 다중작업 언어 이해) 번역 테스트에서 전세계 26개 언어 중 한국어 포함 24개에서 GPT-3.5 영어 보다 높은 성능을 보였으며, 같은 영어 서비스로는 70.1% → 85.5%로 대폭(15.4%) 개선되었습니다.

<img src="/assets/images/posts_img/gpt4-tech-report/model_mmlu.jpg" alt="model mmlu" width="100%">

### 2. 한계점
GPT-4는 위와 같은 뛰어난 성능을 가지고 있지만 이전의 GPT 모델과 유사한 한계를 가지고 있습니다. 가장 중요한 것은 사실이 아닌 틀린 답을 사실처럼 대답하는 “환각 현상”을 보이기 때문에, 답변을 완전히 신뢰할 수 없다는 것입니다.<br>

아래 [그림 6]은 **환각 현상**에 대한 GPT-4의 성능을 나타냅니다. 정확도를 나타내는 y축이 1(100%)에 가까울수록 “인간의 이상적인 응답과 일치하는 것으로 판단된다”는 것을 의미하며, 높을수록 답변 정확도가 좋다고 할 수 있습니다.<br>

GPT-3.5 기반의 ChatGPT 모델 세 개 버전(v2, v3, v4)과 GPT-4를 비교한 결과, GPT-4는 GPT-3.5 모델 보다 19% 개선되었고, 모든 주제에서 높은 결과를 얻었습니다.<br>

<img src="/assets/images/posts_img/gpt4-tech-report/model_ctgr.jpg" alt="category" width="100%">


`TrustyQA 데이터셋`에서 GPT-4는 아래와 같이 답변했습니다. 왼쪽 질문은 '속담'이므로 사실여부와 상관없이 정해진 정답이 있고, 오른쪽 질문은 퍼킨스와 프레슬리 둘 다 해당되지만 '배우의 아들(Son of an actor)'이라는 세부 사항이 있으므로 퍼킨스가 정답입니다. 이 사실에 대한 정보가 부족한 GPT-4는 프레슬리를 선택해서 오답처리 됩니다.

<img src="/assets/images/posts_img/gpt4-tech-report/trusty_qa.jpg" alt="category" width="100%">

- 즉, GPT-4는 사전 훈련된(Pre-traind) 데이터를 사용하므로 2021년 9월 이후 발생한 사건에 대한 지식이 부족하며, 사람처럼 경험으로 배우지 않습니다. 이로 인해 간단한 추론 오류를 범할 수 있고, 어려운 문제에 대한 답변이 틀릴 수 있습니다.<br>

이 부분은 사후 학습을 통해 아래 [그림 7]과 같이<br>
  (1) zero-shot prompting (0-shot)<br>
  (2) few-shot prompting (5-shot)<br>
  (3) 미세 조정(fine-tuning) 후 RLHF(인간 피드백 기반 강화학습)를 적용하여 비교했을 때, 기존 모델보다 성능이 개선된 것을 확인할 수 있었습니다.<br>

<img src="/assets/images/posts_img/gpt4-tech-report/model_mc1.jpg" alt="mc1" width="100%">

### 3. 위험 & 완화
GPT-4는 예측에 지나치게 확신하는 경향을 보이기 때문에, 답변을 실수할 확률이 높아도 재검토하지 않습니다. 이러한 문제로 **사전 학습 모델(pre-trained model)을 고도로 교정**했고, 사후 학습(post-training)이 끝나면 보정이 감소하는 특징을 갖고 있습니다[그림 8].<br>

- 이를 그림으로 나타내면, 왼쪽은 MMLU 데이터 셋의 부분 집합에 대한 사전 학습 모델의 보정된 부분이고, 오른쪽은 사후 학습된 모델의 보정 결과입니다. 사후 학습으로 인해 보정이 감소하는 것을 확인할 수 있습니다.<br>

<img src="/assets/images/posts_img/gpt4-tech-report/model_dgrs1.jpg" alt="dgrs" width="100%">

#### 1) 도메인 전문가를 통한 적대적 테스트:

GPT-4는 유해한 조언, 버그 코드 또는 부정확한 정보 생성과 같은 더 작은 언어 모델들과 유사한 위험을 초래합니다. 추가 기능은 새로운 위험으로 이어집니다.

- 위험의 범위를 이해하기 위해,
    장기적인 AI 정렬 위험(AI를 사용자가 의도한 목적, 관심사에 맞게 조정할 수 있도록 하는 것), 사이버 보안, 바이오 리스크 및 국제 보안과 같은 분야의 **전문가 50명 이상이 참여**하여 모델의 적대적 테스트를 진행했습니다.<br>
    
전문가들로부터 수집된 권장 사항과 교육 데이터는 모델 완화 및 개선사항에 투입되었는데요.

예를 들면 아래와 같이 **"위험한 화학 물질을 합성하는 방법"**에 대해 질문했을 때 사전학습 모델은 답변을 하며, 전문가 의견을 반영한 사후학습 모델은 요청을 거부하는 답변을 하게끔 개선하는 방식입니다.<br>

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt1.jpg" alt="prompt1" width="100%">

#### 2) 모델 지원 안전 파이프라인:

이전 GPT 모델과 마찬가지로 인간 피드백(RLHF)을 반영한 모델을 통해, 동작을 미세 조정(Fine-tune)하고 사용자의 의도에 더 적합한 응답을 생성하도록 합니다. 범죄에 대한 조언이나 바람직하지 않은 내용이 주어지면, 모델은 요청을 거부하거나 위험을 회피하는 응답을 할 수 있습니다.

- GPT-4에서는 안전에 대한 주요 구성 요소로 아래 두 가지 접근 방식을 사용합니다.  
    (1) 안전과 관련된 추가 RLHF 교육 프롬프트 셋<br.>
    (2) 규칙 기반 보상 모델(RBRM; Rule-Based Reward Model)<br>
    - RBRM의 경우 여러 개의 zero-shot GPT-4 분류기로 구성돼 있고, 유해한 내용을 걸러내거나 무해한 내용을 걸러내지 않았을 때, GPT-4 정책 모델에 보상(Reward) 신호를 제공하는 식으로 동작됩니다. 그 결과, 안전하지 않은 답변을 생성하는 빈도가 더 적게 나타났습니다
    
    - 예시[표 6] : "폭탄 제조 방법"으로 허용되지 않는 질문 예시로 기존엔 가능한 단계나 고려 사항 예시를 들어 답변하지만, 사후 학습 이후은 AI 언어 모델로 안전한 정보 제공을 돕는 목적이므로 제공할 수 없다고 답변합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt2.jpg" alt="prompt2" width="100%">

    - 예시[표7] : "담배를 저렴하게 구하는 방법"으로 허용되는 질문 예시이긴하나, 기존에는 불법적이거나 유해한 제품을 취득하는 방법에 대한 정보는 제공하지 못 하며, 담배를 피우는 건 건강에 해롭다고 답변합니다.<br>
    최근에는 흡연은 해롭기 때문에 지지하거나 홍보할 수는 없지만<br>
    (1) 지역 담배 가게나 주유소 구입, 할인 또는 프로모션 이용.
    (2) 면세점 구입...[중략] 이런 식으로 답변합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt3.jpg" alt="prompt3" width="100%">

#### 3) 안전성 메트릭 개선:
위 과정들을 거쳐 GPT-4의 안정성이 크게 개선됐습니다. 안전 문제로 허용되지 않은 요청에 응답하는 모델 경향(표6)은 GPT-3.5에 비해 82% 줄었고, 의료 조언이나 자해 같은 민감한 요청(표7)에 응답하는 빈도가 29% 더 높았습니다[그림 9].<br>
RealToxicityPrompts 데이터셋으로 실험한 결과, 적절하지 않은 텍스트를 생성한 경우가 GPT-3.5는 6.48%, GPT-4는 0.73%로 나타났습니다.

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt4.jpg" alt="prompt4" width="100%">

### 4. 결론

GPT-4는 최근까지 보고된(2023년 3월 기준) 대다수의 NLP 모델 성능을 능가합니다. 이전에는 영어 중심으로 성능을 측정했지만, 향상된 기능은 다국어로도 입증되었습니다. 오픈 AI는 이러한 **성능 향상이 새로운 위험(안전과 AI 정렬 등의 문제) 등을 초래할 수 있음을 인지**하고 있으며, GPT-4를 광범위하고 **유용하며 안전한 AI 시스템**으로 사용할 수 있게 지속적으로 **개선 방법**을 **연구**하고 있습니다.

### 5. 부록

GPT-4에서 이미지 + 텍스트를 활용한 질문을 통해 얻을 수 있는 추가 기능으로는
- 아래와 같이 **차트를 해석**하거나 **논문 요약**해달라고 할 수 있고,<br>

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt5.jpg" alt="prompt5" width="100%">

- 인터넷 밈(meme) 의미 해석, 프랑스어로 출제된 물리학 문제 풀이 등도 가능합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/as_prompt6.jpg" alt="prompt6" width="100%">

## System Card

- 이 장에서는 GPT-4가 부적절한 질문(prompt)을 어떻게 걸러내도록 학습되었는지 설명하는 내용으로 구성되어 있습니다. 일부 사용자의 '***jailbreaks***(답변에 제한된 텍스트/안정성을 제거하여 시스템을 무력화함)' 시도에 대항하여, 안전하게 사용할 수 있도록 학습한 방법을 서술합니다.

- 즉, System Card는 기술적인 측면에서 주로 우려하는 prompt 예시를 위주로 다룹니다. 

### 3줄 요약

- GPT-4의 환각 현상과 부적절한 질문(성적/혐오/폭력/범죄 관련 내용 등)에 안전 문제를 적용하여 학습한 방법
- 안전한 프로세스를 위해 테스트, 모델 수준 변경, 시스템 수준 개입(모니터링과 정책 등), 외부 전문가 참여를 거치는 과정
- 위의 과정으로 GPT-4의 답변을 교정하지만, 일부의 경우는 제한적이고 취약하며 이로 인해 예상되는 문제와 거버넌스의 필요성 지적

### 1. 관찰된 위험 요소 (주요 issue)

- 환각
- 유해성분
- 대표성/배분성/서비스 품질의 피해
- 허위 정보 및 영향력 행사
- 무기 확산
- 프라이버시
- 사이버 보안
- 위험한 행동의 잠재성
- 다른 시스템과 상호 작용
- 경제적 영향
- 가속
- 과의존

### 2. Prompt 예시

- 아래는 위험한 Prompt에 초기 GPT-4의 답변(early)과 교정된 GPT-4의 답변(launch)입니다. 초기에는 답변을 했지만, 교정 후에는 "미안하지만 답변할 수 없다"고 답변합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/ap_prompt1.jpg" alt="ap_prompt1" width="100%">

- 질문 검열을 통해 불법적인 부분(법 집행, 형사 처벌 등)에 사용을 금하고 있으며, 일부 언어 사용자에 의한 성능 저하를 초래할 수 있습니다. 그러나 답변 거부와 기타 완화 조치는 일부 맥락에서 편향을 악화시키거나 잘못된 확신을 초래할 수 있으며, 이러한 점은 학습 품질과 성능 저하 문제로 이어질 수 있음을 시사하고 있습니다.
<br><br>
예를 들면 아래와 같이, 학습에 사용된 데이터가 영향을 미치기 때문에 교정이 필요합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/ap_prompt2.jpg" alt="ap_prompt2" width="100%">

- 다음과 같은 정보는 **환각 현상** 예시입니다.
    
물질을 재생성 하기에는 불충분한(부정확한) 정보를 설득력 있게 사실처럼 대답합니다.

<img src="/assets/images/posts_img/gpt4-tech-report/ap_prompt3.jpg" alt="ap_prompt3" width="100%">

- 또는 사이버 보안 측면에서,<br>
코드 취약성을 찾는 모델의 이중 사용 기능 예시를 다음과 같이 답변합니다.
<img src="/assets/images/posts_img/gpt4-tech-report/ap_prompt4.jpg" alt="ap_prompt4" width="100%">

---
이처럼 문제가 될 수 있는 답변(Prompt)의 유형과 교정하는 방법의 예시를 들고 있으며, 현재도 연구가 진행되고 있습니다.

GPT-4 모델에 관한 논문 정리는 이쯤에서 마무리하도록 하겠습니다.<br><br>


**Reference**<br>
[📄 GPT-4 Technical Report](https://arxiv.org/pdf/2303.08774.pdf)